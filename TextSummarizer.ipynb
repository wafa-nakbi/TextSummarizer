{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSummarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0JbvM9xE4kC"
      },
      "source": [
        "**Install transformers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz0nKDM8R2JY",
        "outputId": "940b705f-eb37-4e63-e276-679ddf01cf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "!pip install transformers "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 26.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 18.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 16.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 13.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 12.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 11.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 11.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 11.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 11.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 11.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 11.1MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 11.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 11.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 11.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=7046feafa6a121cd2a3c696fdd12566f08d0b77e71f24a163c3637ec49a0af97\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he87Jow9OFSy"
      },
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "import datetime\n",
        "import os\n",
        "import gc\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Wuo9gOO077"
      },
      "source": [
        "**Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWzixm_COoty",
        "outputId": "9954ae49-9727-45e8-947c-34db5c634dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "train_data, info = tfds.load('cnn_dailymail', split = 'train', data_dir = 'data/', with_info=True)\n",
        "test_data = tfds.load('cnn_dailymail', split = 'test', data_dir = 'data/')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: cnn_dailymail/plain_text\n",
            "INFO:absl:Overwrite dataset info from restored data version.\n",
            "INFO:absl:Reusing dataset cnn_dailymail (data/cnn_dailymail/plain_text/3.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train, from data/cnn_dailymail/plain_text/3.0.0\n",
            "INFO:absl:No config specified, defaulting to first: cnn_dailymail/plain_text\n",
            "INFO:absl:Overwrite dataset info from restored data version.\n",
            "INFO:absl:Reusing dataset cnn_dailymail (data/cnn_dailymail/plain_text/3.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test, from data/cnn_dailymail/plain_text/3.0.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbtrQ9gBFepK"
      },
      "source": [
        "**Fine tune the T5 model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngctUoOtdzSU"
      },
      "source": [
        "class T5Model(TFT5ForConditionalGeneration):\n",
        "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "    \n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        x = data[0]\n",
        "        y = x['labels']\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = self(inputs = x['inputs'], attention_mask = x['attention_mask'], labels = y, training=True, return_dict=True)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            loss = tf.reduce_mean(loss)\n",
        "            grads = tape.gradient(loss, self.trainable_variables)\n",
        "            \n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables)) \n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "        metrics.update({'loss': loss})\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x = data[0]\n",
        "        y = x['labels']\n",
        "        output = self(inputs = x['inputs'], attention_mask = x['attention_mask'], labels = y, training=False, return_dict=True)\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "        metrics.update({'loss': loss})\n",
        "        return metrics\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gPMKzWnF5Kj"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYoVCDZYtj1e"
      },
      "source": [
        "model_path = './t5/models'\n",
        "log_path = './t5/logs'\n",
        "config = {\n",
        "    'batch_size' : 4,\n",
        "    'epochs' : 1,\n",
        "    'learning_rate' :1e-4,\n",
        "    'max_len' : 512,\n",
        "    'summary_len' : 150\n",
        "}\n",
        "data_size = {\n",
        "    'train': 10000,\n",
        "    'test' : 1000\n",
        "}\n",
        "params = {'source_len' : 512,\n",
        "          'target_len' : 150,\n",
        "          'batch_size' : 4\n",
        "          }\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo6Y-_uqdFXQ"
      },
      "source": [
        "**Encode and generate data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krLSJemQtvn7"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def  __init__(self, data, tokenizer, mode, source_len, target_len, batch_size):\n",
        "   self.data = data\n",
        "   self.tokenizer = tokenizer\n",
        "   self.source_len = source_len\n",
        "   self.target_len = target_len\n",
        "   self.batch_size = batch_size\n",
        "   self.mode = mode\n",
        "\n",
        "  def __len__(self):\n",
        "     return int(np.ceil(data_size[self.mode]/self.batch_size))\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    dataset_batch = self.data.skip(self.batch_size).take(self.batch_size)\n",
        "    encoded_batch = self.encode_data(dataset_batch, self.tokenizer, self.source_len , self.target_len)\n",
        "    return encoded_batch\n",
        "\n",
        "  def encode_data(self, data, tokenizer, source_len , target_len ):\n",
        "    source = data.map(lambda text: 'summarize: ' + text['article'])\n",
        "    source = list(map(lambda text: str(text,'utf-8'),list(tfds.as_numpy(source))))\n",
        "    target = data.map(lambda text: text['highlights'])\n",
        "    target = list(map(lambda text: str(text,'utf-8'),list(tfds.as_numpy(target))))\n",
        "\n",
        "    batch_encoding = tokenizer.prepare_seq2seq_batch(\n",
        "        src_texts = source,\n",
        "        tgt_texts =  target,\n",
        "        max_length= source_len, \n",
        "        max_target_length= target_len,\n",
        "        padding = 'max_length',\n",
        "        return_tensors = 'tf')\n",
        "    batch_encoding['labels'] = tf.where(batch_encoding['labels']==tokenizer.pad_token_id, -100, batch_encoding['labels'])\n",
        "\n",
        "    return {'inputs' : batch_encoding['input_ids'], \n",
        "            'attention_mask' : batch_encoding['attention_mask'],\n",
        "            'labels':batch_encoding['labels']\n",
        "            } \n",
        "\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHA7a2HJ8_4y"
      },
      "source": [
        "training_data = DataGenerator(train_data.take(data_size['train']), tokenizer, 'train', **params)\n",
        "validation_data = DataGenerator(test_data.take(data_size['test']), tokenizer, 'test', **params)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeG4YihNhw-M"
      },
      "source": [
        "**Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMccn_dPh1EP"
      },
      "source": [
        "log_dir = log_path + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "                                                     \n",
        "checkpoint_filepath = model_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks = [tensorboard_callback, model_checkpoint_callback] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7bICJcilYq0"
      },
      "source": [
        "**Create the T5 model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Nx8bFchoKv",
        "outputId": "ab76ace0-4790-4492-bdcd-fbcaa4c3cebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "\n",
        "def create_model():\n",
        "  model = T5Model.from_pretrained(\"t5-base\")\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=config['learning_rate'])\n",
        "  metrics = tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')\n",
        "  model.compile(optimizer=optimizer, metrics = metrics)\n",
        "  return model\n",
        "model = create_model()\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing T5Model.\n",
            "\n",
            "All the layers of T5Model were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5Model for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs73CkY3ly3l"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4E6vUBjlqhs",
        "outputId": "887ec147-b12b-4ef3-9136-29ae9abf7cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "\n",
        "epochs = config['epochs']\n",
        "model.fit( training_data, validation_data = validation_data, epochs = epochs)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - 2139s 855ms/step - accuracy: 0.4892 - loss: 0.0098 - val_accuracy: 0.2750 - val_loss: 3.1186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f65855135f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB1vQ4rPJKrI"
      },
      "source": [
        "**Save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVarDXGlpkkI"
      },
      "source": [
        "model.save_pretrained(model_path)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9EqnBE1WoJW",
        "outputId": "25cc9bd6-46f5-4800-c8f1-6c0be9645526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        ""
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/t5/ (stored 0%)\n",
            "  adding: content/t5/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/t5/models/ (stored 0%)\n",
            "  adding: content/t5/models/tf_model.h5 (deflated 11%)\n",
            "  adding: content/t5/models/config.json (deflated 64%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B8AXABRV6r5",
        "outputId": "9d499cb0-58b4-43ce-a159-be8686106f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        }
      },
      "source": [
        "!zip -r t5.zip /content/t5\n",
        "from google.colab import files\n",
        "files.download(\"/content/t5.zip\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bd7a9459-1d0a-4f0c-9dc1-5fabb25f33f6\", \"t5.zip\", 794301387)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIYTeQRUmCJt"
      },
      "source": [
        "**Download a test text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX4ur-gdDtMP",
        "outputId": "9cdf4d73-982b-41e4-cb90-fcc29c207891",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3afec86-4a80-41eb-9101-4fa846892c79\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3afec86-4a80-41eb-9101-4fa846892c79\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving testfile01.txt to testfile01.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unj-UAOJD2Ac"
      },
      "source": [
        "with open('/content/test.txt', 'r') as f:\n",
        "  source_txt = f.read()\n",
        "source_txt = 'summarize: ' + source_txt \n",
        "#print (source_txt)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQBCr3UJmNMR"
      },
      "source": [
        "**Test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCTKzdGuK_h-",
        "outputId": "4d35df7b-5533-4dff-b085-490aababdd35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "source = tokenizer.prepare_seq2seq_batch(\n",
        "      src_texts = source_txt,\n",
        "      max_length=512, \n",
        "      padding = 'max_length',\n",
        "      return_tensors = 'tf')\n",
        "input_ids = source['input_ids']\n",
        "attention_mask = source['attention_mask']\n",
        "'''summary = model.generate(input_ids = input_ids,\n",
        "                attention_mask = attention_mask,\n",
        "                 max_length=150, num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True)'''\n",
        "summary = model.generate(input_ids = input_ids,\n",
        "                attention_mask = attention_mask, \n",
        "                max_length=150, \n",
        "                num_beams=3,\n",
        "                no_repeat_ngram_size=2, \n",
        "                early_stopping=True)                          \n",
        "decoded_summary = tokenizer.decode(summary.numpy()[0])\n",
        "print ('Summary:\\n', decoded_summary)\n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary:\n",
            " Riverhead High School on Long Island, New York. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the 'Tebowing' craze was blocking the hallway and present a safety hazard to students.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}